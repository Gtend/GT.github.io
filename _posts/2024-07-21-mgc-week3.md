---
title: 2024-1 하계 모각코 3주차
layout: post
date: '2024-07-21 18:00:00'
icon: github
category: mgc
---

## 하계 모각코 3주차 공부 내용 정리
### 😀학번, 이름 : 202102552, 유채민

### 🎯오늘의 계획
#### 🎡목표
- 대조 학습, 반 지도 학습 관련 학습

#### ☑️결과
# 1. 대조학습(Contrastive Learning)
 - 개요
대조학습은 주로 자기지도학습(self-supervised learning)에서 사용되는 방법으로, 비슷한 샘플들은 가까이, 다른 샘플들은 멀리 위치하도록 학습하는 방법
이 접근법은 레이블이 없는 데이터를 활용해 강력한 특징 표현(feature representation)을 학습
 - 주요 개념
포지티브 페어 (Positive Pairs): 서로 유사한 두 샘플. 예를 들어, 동일 이미지의 변형된 두 버전
네거티브 페어 (Negative Pairs): 서로 다른 두 샘플. 예를 들어, 서로 다른 이미지
대조 손실 (Contrastive Loss): 포지티브 페어의 거리를 가깝게 하고 네거티브 페어의 거리를 멀게 만드는 손실 함수. 대표적으로 InfoNCE Loss
 - 대표적인 방법론
SimCLR: 데이터 변형(augmentation)을 통해 생성된 샘플들을 사용하여 학습하는 방식으로, 대조 손실을 통해 표현을 학습
MoCo (Momentum Contrast): 대규모 배치를 필요로 하지 않고 메모리를 효율적으로 사용하는 방법으로, 큐(queue)와 모멘텀 업데이트(momentum update)를 활용
# 2. 반지도학습(Semi-Supervised Learning)
 - 개요
반지도학습은 레이블이 있는 소량의 데이터와 레이블이 없는 대량의 데이터를 함께 사용하여 모델을 학습하는 방법
주로 레이블링이 어려운 대규모 데이터셋에서 성능을 향상시키는 데 사용
 - 주요 개념
지도 데이터 (Labeled Data): 레이블이 포함된 데이터
비지도 데이터 (Unlabeled Data): 레이블이 없는 데이터, 모델이 이 데이터에서 유용한 정보(예: 클러스터링이나 경계)를 학습하도록 유도
Consistency Regularization: 비지도 데이터의 예측 결과가 작은 변동에 대해 일관성을 유지하도록 하는 제약 조건
Entropy Minimization: 모델이 비지도 데이터에 대해 더 확신을 갖고 예측하도록 하는 전략
 - 대표적인 방법론
Pseudo-Labeling: 모델이 비지도 데이터에 대해 예측한 라벨을 '가짜 라벨'로 간주하고, 이를 학습에 사용하는 방법
Mean Teacher: 학생-교사 구조를 사용하여, 교사 모델의 예측을 참조하여 학생 모델이 비지도 데이터를 학습하도록 유도
FixMatch: Consistency Regularization과 Pseudo-Labeling을 결합한 방법으로, 강력한 데이터 변형 후 예측이 일관된 경우에만 Pseudo-Label로 학습
